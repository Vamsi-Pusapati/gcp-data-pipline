# Medicaid Drug Data Pipeline - GCP

Production-grade, event-driven data pipeline for extracting, processing, enriching, and visualizing Medicaid drug pricing data on Google Cloud Platform.

## üéØ Project Overview

This project implements a complete end-to-end, automated data pipeline with AI capabilities:

1. **Extract** - Airflow DAG orchestrates API data extraction from Medicaid
2. **Store** - Raw JSON data stored in GCS with Pub/Sub notifications
3. **Load** - Event-driven Cloud Run Function loads data to BigQuery staging
4. **Enrich** - Dataproc PySpark job transforms and enriches data
5. **Visualize** - Streamlit dashboard on GKE with real-time analytics
6. **AI Assistant** - RAG-powered chatbot using Vertex AI for natural language queries

## üèóÔ∏è System Architecture (Physical Deployment)

```mermaid
graph TB
    subgraph GCP_Project["GCP Project: gcp-project-deliverable"]
        subgraph Networking["VPC: medicaid-vpc (us-central1)"]
            Subnet1["Subnet: data-pipeline-subnet"]
        end

        subgraph ArtifactLayer["Artifact & Images"]
            AR["Artifact Registry<br/>Repo: docker/streamlit-dashboard"]
            ARFunc["Artifact Registry<br/>Repo: docker/cloud-run-func"]
        end

        subgraph ComposerEnv["Cloud Composer (Airflow)"]
            ComposerSched["Extraction DAG<br/>medicaid_data_dag"]
            ComposerEnrich["Enrichment DAG<br/>medicaid_enrichment_dag"]
        end

        subgraph StorageLayer["Cloud Storage Buckets"]
            GCSRaw[("Bucket: medicaid-data/raw/")]
            GCSProcessed[("Bucket: medicaid-data/processed/")]
        end

        subgraph Messaging["Pub/Sub"]
            TopicRaw[("Topic: gcs-raw-files")]
            DLQ[("DLQ Subscription (optional)")]
        end

        subgraph IngestionCompute["Serverless Ingestion"]
            CloudRunFn["Cloud Run Service<br/>gcs-to-bigquery"]
        end

        subgraph BigQueryLayer["BigQuery"]
            BQTableStage[("medicaid_staging.nadac_drugs")]
            BQTableEnriched[("medicaid_enriched.nadac_drugs_enriched")]
        end

        subgraph DataprocLayer["Dataproc (Ephemeral Cluster)"]
            DataprocJob["PySpark Job<br/>data_processing_job.py"]
        end

        subgraph GKECluster["GKE Cluster: medicaid-dashboard-cluster"]
            StreamlitDeploy["Deployment: streamlit-dashboard"]
            StreamlitSvc["Service: LoadBalancer"]
        end

        subgraph VertexAILayer["Vertex AI"]
            Embeddings["Embedding Model<br/>text-embedding-gecko"]
            VectorIndex["FAISS Index (in pod / disk)"]
            LLM["Gemini Pro API"]
        end

        subgraph Observability["Logging & Monitoring"]
            CloudLogs["Cloud Logging"]
            Metrics["Cloud Monitoring"]
        end

        subgraph IAM["IAM / Security"]
            SA_Pipeline["Single Service Account:<br/>data-pipeline-sa<br/>(WI binding for GKE, Cloud Run, Composer, Dataproc)"]
        end

        ComposerSched -->|REST API Call| MedicaidAPI[("External Medicaid API")]
        ComposerSched -->|Write JSON| GCSRaw
        GCSRaw -->|Object Finalize| TopicRaw --> CloudRunFn
        CloudRunFn -->|Read JSON| GCSRaw
        CloudRunFn -->|Load Rows| BQTableStage
        CloudRunFn -->|Archive File| GCSProcessed
        ComposerEnrich -->|Trigger PySpark| DataprocJob
        BQTableStage --> DataprocJob -->|Write Enriched| BQTableEnriched
        StreamlitDeploy -->|Query| BQTableEnriched
        BQTableEnriched -->|Embeddings| Embeddings --> VectorIndex -->|Context| LLM --> StreamlitDeploy

        %% Single SA permissions fan-out
        SA_Pipeline --> ComposerSched
        SA_Pipeline --> ComposerEnrich
        SA_Pipeline --> CloudRunFn
        SA_Pipeline --> DataprocJob
        SA_Pipeline --> StreamlitDeploy

        %% Observability
        CloudRunFn --> CloudLogs
        DataprocJob --> CloudLogs
        StreamlitDeploy --> CloudLogs
        CloudLogs --> Metrics
    end

    EndUsers((End Users Browser)) --> StreamlitSvc --> StreamlitDeploy
    StreamlitDeploy --> AR
    CloudRunFn --> ARFunc
```

ASCII Fallback (Physical Overview):
```
[End Users] -> [GKE LB Service] -> [Streamlit Pods] -> [BigQuery Enriched]
Extraction DAG -> Medicaid API -> GCS raw/ -> Pub/Sub -> Cloud Run -> BigQuery Staging -> GCS processed/
Enrichment DAG -> Dataproc PySpark -> BigQuery Enriched
BigQuery Enriched -> Embeddings -> FAISS -> Gemini Pro -> Streamlit Chatbot
Single Service Account (medicaid-pipeline-sa) via Workload Identity grants access to: GCS, Pub/Sub, BigQuery, Dataproc, Vertex AI
```

Physical Characteristics:
- Region: us-central1  
- Single Service Account simplifies IAM; ensure scoped roles (Storage Object Viewer, Pub/Sub Subscriber, BigQuery Data Editor, Dataproc Worker, Vertex AI User)  
- Event-driven ingestion decoupled via Pub/Sub  
- Ephemeral Dataproc cluster lowers cost  
- Streamlit on GKE for scalable presentation & chatbot integration  
- Shared enriched dataset powers both analytics & RAG  

## üîÑ Data Flow Diagram

```mermaid
graph TB
    subgraph Phase1["Phase 1: Extraction"]
        P1_DAG["Extraction DAG"] --> P1_API[(Medicaid API)]
        P1_DAG -->|JSON| P1_GCS[(GCS raw/)]
    end
    P1_GCS -->|Finalize Event| EVT[(Pub/Sub gcs-raw-files)]
    subgraph Phase2["Phase 2: Ingestion"]
        EVT --> FN["Cloud Run<br/>gcs-to-bigquery"]
        FN -->|Rows| STAGE[(BigQuery Staging)]
        FN -->|Archive| PROC[(GCS processed/)]
    end
    subgraph Phase3["Phase 3: Enrichment"]
        ENRICH_DAG["Enrichment DAG"] --> SPARK[(Dataproc PySpark)]
        STAGE --> SPARK --> ENRICHED[(BigQuery Enriched)]
    end
    subgraph Phase4["Phase 4: Serving"]
        DASH["Streamlit Dashboard<br/>GKE"] -->|Query| ENRICHED
    end
    subgraph Phase5["Phase 5: AI Assistant"]
        ENRICHED --> EMB["Embeddings<br/>gecko"]
        EMB --> IDX["FAISS Index"]
        IDX --> LLM["Gemini Pro"]
        LLM --> DASH
    end
    USERS((End Users)) --> DASH
```

Flow Steps:
1. DAG pulls API -> stores JSON.
2. GCS finalize -> Pub/Sub event.
3. Cloud Run validates + loads staging; archives.
4. Enrichment DAG triggers Dataproc -> enriched table.
5. Dashboard queries enriched data.
6. RAG builds embeddings + FAISS; Gemini answers.
7. Users view charts & chat.

## ÔøΩ Component Details

### 1Ô∏è‚É£ Data Extraction (Cloud Composer)
- **File**: `composer/dags/medicaid_data_dag.py`
- **Trigger**: Scheduled (e.g., daily)
- **Process**: Calls Medicaid API ‚Üí Saves JSON to GCS raw/
- **Output**: `gs://medicaid-data/raw/drug_data_YYYYMMDD.json`

### 2Ô∏è‚É£ Event-Driven Ingestion
- **Pub/Sub**: Triggers on GCS Object Finalize
- **Cloud Run Function**: `cloud-functions/gcs-to-bq/main.py`
  - Reads JSON from GCS
  - Loads to BigQuery staging
  - Moves file to processed/

### 3Ô∏è‚É£ Data Enrichment (Dataproc)
- **Orchestration**: `composer/dags/medicaid_enrichment_dag.py`
- **Job**: `dataproc/data_processing_job.py` (PySpark)
  - Parses drug names into components
  - Maps explanation codes
  - Writes to enriched table

### 4Ô∏è‚É£ Dashboard (GKE)
- **App**: `dashboard/app.py` (Streamlit)
- **Deployment**: Docker ‚Üí Artifact Registry ‚Üí GKE
- **Features**: Charts, filters, real-time BigQuery queries, AI chatbot

### 5Ô∏è‚É£ RAG AI System (Vertex AI)
- **Notebook**: `notebooks/drug_rag_system.ipynb`
- **Components**: Embeddings (Gecko) + Vector Store (FAISS) + LLM (Gemini)
- **Integration**: Chatbot in Streamlit dashboard

## ÔøΩüì¶ Project Structure

```
GCS_Project/
‚îú‚îÄ‚îÄ cloud-functions/
‚îÇ   ‚îî‚îÄ‚îÄ gcs-to-bq/
‚îÇ       ‚îî‚îÄ‚îÄ main.py                      # Event-driven ingestion function
‚îÇ
‚îú‚îÄ‚îÄ dataproc/
‚îÇ   ‚îî‚îÄ‚îÄ data_processing_job.py           # PySpark enrichment job
‚îÇ
‚îú‚îÄ‚îÄ composer/
‚îÇ   ‚îî‚îÄ‚îÄ dags/
‚îÇ       ‚îú‚îÄ‚îÄ medicaid_data_dag.py         # Extraction DAG
‚îÇ       ‚îî‚îÄ‚îÄ medicaid_enrichment_dag.py   # Enrichment DAG
‚îÇ
‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                           # Streamlit dashboard
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ k8s/                             # Kubernetes manifests
‚îÇ   ‚îú‚îÄ‚îÄ deploy-gke.ps1                   # Deployment script (Windows)
‚îÇ   ‚îú‚îÄ‚îÄ build-image.ps1                  # Build script (Windows)
‚îÇ   ‚îú‚îÄ‚îÄ verify-setup.ps1                 # Setup verification
‚îÇ   ‚îú‚îÄ‚îÄ manage-dashboard.ps1             # Management script
‚îÇ   ‚îú‚îÄ‚îÄ QUICKSTART.md                    # 5-minute deployment guide
‚îÇ   ‚îú‚îÄ‚îÄ README.md                        # Complete dashboard docs
‚îÇ   ‚îú‚îÄ‚îÄ DEPLOYMENT.md                    # Detailed deployment
‚îÇ   ‚îî‚îÄ‚îÄ TOOLKIT.md                       # Complete script reference
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                           # NEW: RAG AI System
‚îÇ   ‚îú‚îÄ‚îÄ drug_rag_system.ipynb           # Complete RAG implementation
‚îÇ   ‚îú‚îÄ‚îÄ README.md                        # RAG documentation
‚îÇ   ‚îú‚îÄ‚îÄ QUICKSTART.md                    # 15-minute setup guide
‚îÇ   ‚îú‚îÄ‚îÄ DEPLOYMENT_GUIDE.md              # Production deployment
‚îÇ   ‚îú‚îÄ‚îÄ OVERVIEW.md                      # Architecture details
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                 # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ rag_api.py                       # FastAPI service
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                       # Container for API
‚îÇ   ‚îî‚îÄ‚îÄ setup_rag.py                     # Automated setup
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup-gcs.sh                     # GCS bucket setup
‚îÇ   ‚îú‚îÄ‚îÄ setup-bigquery.sh                # BigQuery setup
‚îÇ   ‚îî‚îÄ‚îÄ setup-dataproc.sh                # Dataproc setup
‚îÇ
‚îú‚îÄ‚îÄ cloudbuild.yaml                      # Cloud Build config
‚îú‚îÄ‚îÄ .gitignore                           # Git exclusions
‚îî‚îÄ‚îÄ README.md                            # This file
```

## üöÄ Quick Start

### Prerequisites

- ‚úÖ Google Cloud SDK (`gcloud`) installed
- ‚úÖ Authenticated: `gcloud auth login`
- ‚úÖ Project: `gcp-project-deliverable`
- ‚úÖ APIs enabled: Composer, Dataproc, GKE, Cloud Run, Pub/Sub, Artifact Registry

### Setup Pipeline

```bash
# 1. Setup GCS buckets and Pub/Sub
./scripts/setup-gcs.sh

# 2. Setup BigQuery datasets and tables
./scripts/setup-bigquery.sh

# 3. Deploy Cloud Run Function
cd cloud-functions/gcs-to-bq
gcloud functions deploy gcs-to-bigquery \
  --runtime python310 \
  --trigger-topic gcs-raw-files \
  --entry-point process_gcs_file

# 4. Deploy Airflow DAGs to Composer
gcloud composer environments storage dags import \
  --environment medicaid-composer \
  --location us-central1 \
  --source composer/dags/

# 5. Deploy Dashboard to GKE
cd dashboard
./deploy-gke.ps1
```

### Test the Pipeline

```bash
# Trigger extraction DAG
gcloud composer environments run medicaid-composer \
  --location us-central1 \
  dags trigger -- medicaid_data_dag

# Monitor progress
# 1. Check GCS for raw files
gsutil ls gs://medicaid-data/raw/

# 2. Check BigQuery staging
bq query --use_legacy_sql=false \
  'SELECT COUNT(*) FROM medicaid_staging.nadac_drugs'

# 3. Trigger enrichment
gcloud composer environments run medicaid-composer \
  --location us-central1 \
  dags trigger -- medicaid_enrichment_dag

# 4. Check enriched data
bq query --use_legacy_sql=false \
  'SELECT COUNT(*) FROM medicaid_enriched.nadac_drugs_enriched'

# 5. Access dashboard
kubectl get service streamlit-dashboard
```

## üîß Configuration

### GCP Resources

| Resource | Name/ID | Purpose |
|----------|---------|---------|
| Project | `gcp-project-deliverable` | Main GCP project |
| GCS Bucket (Raw) | `medicaid-data/raw/` | Raw JSON files |
| GCS Bucket (Processed) | `medicaid-data/processed/` | Archived files |
| Pub/Sub Topic | `gcs-raw-files` | Event notifications |
| Cloud Run Function | `gcs-to-bigquery` | Event-driven ingestion |
| BigQuery Dataset (Staging) | `medicaid_staging` | Raw data tables |
| BigQuery Table (Staging) | `nadac_drugs` | Staging table |
| BigQuery Dataset (Enriched) | `medicaid_enriched` | Processed data |
| BigQuery Table (Enriched) | `nadac_drugs_enriched` | Enriched table |
| Composer Environment | `medicaid-composer` | Airflow orchestration |
| Dataproc Cluster | Ephemeral | PySpark processing |
| GKE Cluster | `medicaid-dashboard-cluster` | Dashboard hosting |
| Artifact Registry | `docker` | Container images |

## üéØ Key Features

### Event-Driven Architecture
‚úÖ **Automatic Processing**: Files uploaded to GCS trigger automatic ingestion  
‚úÖ **Scalable**: Pub/Sub handles high-volume events  
‚úÖ **Reliable**: Dead letter queues for failed messages  
‚úÖ **Auditable**: Cloud Logging tracks all events

### Orchestrated Workflows
‚úÖ **Scheduled Extraction**: Daily API calls via Airflow  
‚úÖ **Automated Enrichment**: Triggered after ingestion  
‚úÖ **Monitoring**: Airflow UI shows pipeline status  
‚úÖ **Retries**: Automatic retry on failures

### Production-Ready Dashboard
‚úÖ **Containerized**: Docker image in Artifact Registry  
‚úÖ **Scalable**: Auto-scales 1-4 replicas on GKE  
‚úÖ **Secure**: Workload Identity (no service account keys)  
‚úÖ **Real-time**: Live BigQuery queries

### AI-Powered Insights
‚úÖ **Natural Language Queries**: Ask questions in plain English  
‚úÖ **Semantic Search**: Understands intent, not just keywords  
‚úÖ **Conversational**: Multi-turn dialogues with context  
‚úÖ **Accurate**: Cites source drugs in responses

## üìä Data Pipeline Details

### Phase 1: Extraction (Airflow DAG)
**Frequency**: Scheduled (e.g., daily at 2 AM UTC)  
**File**: `composer/dags/medicaid_data_dag.py`

**Steps**:
1. Call Medicaid Drug Pricing API (REST API)
2. Receive JSON response with drug data
3. Save to GCS: `gs://medicaid-data/raw/drug_data_YYYYMMDD_HHMMSS.json`
4. Log success/failure to Cloud Logging

**Sample Data**:
```json
{
  "ndc": "00000-0000-00",
  "ndc_description": "IBUPROFEN 200MG TABLET",
  "nadac_per_unit": "0.03456",
  "effective_date": "2024-01-01",
  ...
}
```

### Phase 2: Ingestion (Event-Driven)
**Trigger**: GCS Object Finalize Event  
**Function**: `cloud-functions/gcs-to-bq/main.py`

**Process Flow**:
1. File saved to `raw/` folder ‚Üí Pub/Sub notification sent
2. Cloud Run Function triggered by Pub/Sub message
3. Function reads file path from event
4. Downloads and parses JSON from GCS
5. Validates data schema
6. Inserts records into `medicaid_staging.nadac_drugs`
7. Moves file to `processed/` folder
8. Updates processing log

**Benefits**:
- ‚ö° **Real-time**: Processes files immediately
- üîÑ **Automatic**: No manual intervention needed
- üìà **Scalable**: Handles multiple files concurrently
- üõ°Ô∏è **Reliable**: Dead letter queue for failed events

### Phase 3: Enrichment (Dataproc PySpark)
**Trigger**: Manual or scheduled via Airflow DAG  
**File**: `dataproc/data_processing_job.py`  
**Orchestration**: `composer/dags/medicaid_enrichment_dag.py`

**Processing Steps**:
1. **Read Staging Data**:
   ```python
   staging_df = spark.read.format("bigquery") \
       .option("table", "medicaid_staging.nadac_drugs") \
       .load()
   ```

2. **Parse Drug Names**:
   - Input: `"IBUPROFEN 200MG TABLET"`
   - Extract:
     - `drug_name`: "IBUPROFEN"
     - `drug_strength`: "200"
     - `drug_dosage`: "MG"
     - `drug_form`: "TABLET"

3. **Map Explanation Codes**:
   - Input: `explanation_code` = "1,2"
   - Output: `explanation_code_description` = "Calculated from pharmacy survey | Carried forward"

4. **Add Metadata**:
   - `enriched_timestamp`: Current timestamp
   - Data quality flags

5. **Write to Enriched Table**:
   ```python
   enriched_df.write.format("bigquery") \
       .option("table", "medicaid_enriched.nadac_drugs_enriched") \
       .save()
   ```

**Performance**:
- 50,000 records: ~5-10 minutes
- Cluster: 1 master + 2 workers (auto-scaled)
- Cost: ~$0.50-1.00 per run

### Phase 4: Visualization (Streamlit on GKE)
**Deployment**: Docker ‚Üí Artifact Registry ‚Üí GKE  
**File**: `dashboard/app.py`

**Build & Deploy Process**:
```powershell
# 1. Build Docker image
docker build -t us-central1-docker.pkg.dev/gcp-project-deliverable/docker/streamlit-dashboard:latest .

# 2. Push to Artifact Registry
docker push us-central1-docker.pkg.dev/gcp-project-deliverable/docker/streamlit-dashboard:latest

# 3. Deploy to GKE
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml

# 4. Get external IP
kubectl get service streamlit-dashboard
```

**Features**:
- üìä **Interactive Charts**: Bar, pie, line, scatter plots
- üîç **Dynamic Filters**: Drug name, date range, form, classification
- üìà **Real-time Queries**: Live BigQuery data
- üí¨ **AI Chatbot**: Integrated RAG system
- üîê **Secure**: Workload Identity authentication
- ‚ö° **Auto-scaling**: 1-4 replicas based on CPU

**Dashboard Queries**:
```python
# Example: Get average price by drug
query = f"""
    SELECT drug_name, AVG(nadac_per_unit) as avg_price
    FROM `medicaid_enriched.nadac_drugs_enriched`
    WHERE drug_name IS NOT NULL
    GROUP BY drug_name
    ORDER BY avg_price DESC
    LIMIT 20
"""
df = client.query(query).to_dataframe()
```

### Phase 5: AI Assistant (RAG System)
**Notebook**: `notebooks/drug_rag_system.ipynb`  
**Technology**: Vertex AI + FAISS

**RAG Pipeline**:
1. **Load Data**: Read enriched table from BigQuery
2. **Generate Embeddings**: Convert drugs to 768-dim vectors (Vertex AI)
3. **Build Vector Store**: Create FAISS index for similarity search
4. **Query Processing**: 
   - User asks question
   - Generate query embedding
   - Search top-k similar drugs
   - Format context
5. **Answer Generation**: Gemini Pro creates natural language response

**Example Interaction**:
```
User: "What are affordable pain medications in tablet form?"
RAG:  "Based on the Medicaid database, here are affordable pain 
       medications available in tablet form:
       
       1. Ibuprofen 200MG Tablet - $0.03 per tablet (NDC: 12345-678-90)
          Available at: Community pharmacy
          Type: Over-the-counter
       
       2. Acetaminophen 325MG Tablet - $0.02 per tablet (NDC: 23456-789-01)
          Available at: Community pharmacy
          Type: Over-the-counter
       ..."
```

**Integration with Dashboard**:
- Chatbot widget in Streamlit UI
- Multi-turn conversations
- Source citations with drug details
- Context-aware follow-ups

**See [notebooks/README.md](notebooks/README.md) for setup guide.**

## üîß Management & Monitoring

### Monitoring Dashboard Access

```bash
# Get dashboard URL
kubectl get service streamlit-dashboard -o jsonpath='{.status.loadBalancer.ingress[0].ip}'

# Check pod status
kubectl get pods -l app=streamlit-dashboard

# View logs
kubectl logs -l app=streamlit-dashboard --tail=100

# Describe service
kubectl describe service streamlit-dashboard
```

### Airflow Monitoring

```bash
# Access Composer/Airflow UI
gcloud composer environments describe medicaid-composer \
  --location us-central1 \
  --format="get(config.airflowUri)"

# Trigger DAG manually
gcloud composer environments run medicaid-composer \
  --location us-central1 \
  dags trigger -- medicaid_data_dag

# Check DAG run status
gcloud composer environments run medicaid-composer \
  --location us-central1 \
  dags list-runs -- --dag-id medicaid_data_dag
```

### Cloud Function Monitoring

```bash
# View function logs
gcloud functions logs read gcs-to-bigquery --limit 50

# Get function details
gcloud functions describe gcs-to-bigquery

# Check invocations
gcloud functions logs read gcs-to-bigquery \
  --filter="severity>=WARNING" \
  --limit 100
```

### BigQuery Monitoring

```bash
# Check staging table
bq show medicaid_staging.nadac_drugs
bq query --use_legacy_sql=false \
  'SELECT COUNT(*), MAX(effective_date) FROM medicaid_staging.nadac_drugs'

# Check enriched table
bq show medicaid_enriched.nadac_drugs_enriched
bq query --use_legacy_sql=false \
  'SELECT COUNT(*), MAX(enriched_timestamp) FROM medicaid_enriched.nadac_drugs_enriched'

# View recent data
bq query --use_legacy_sql=false \
  'SELECT * FROM medicaid_enriched.nadac_drugs_enriched 
   ORDER BY enriched_timestamp DESC LIMIT 10'
```

### GCS Monitoring

```bash
# List raw files
gsutil ls -lh gs://medicaid-data/raw/

# List processed files
gsutil ls -lh gs://medicaid-data/processed/

# Check bucket size
gsutil du -sh gs://medicaid-data/

# View file content
gsutil cat gs://medicaid-data/raw/drug_data_20240101_120000.json | head
```

## üö® Troubleshooting

### Dashboard Issues

```powershell
cd dashboard

# Check status
.\manage-dashboard.ps1 -Action status

# View logs
.\manage-dashboard.ps1 -Action logs

# Verify setup
.\verify-setup.ps1

# Restart
.\manage-dashboard.ps1 -Action restart
```

### Pub/Sub Not Triggering

```bash
# Verify Pub/Sub topic exists
gcloud pubsub topics describe gcs-raw-files

# Check subscriptions
gcloud pubsub subscriptions list --filter="topic=gcs-raw-files"

# Verify notification configuration
gsutil notification list gs://medicaid-data/raw/

# Test manually
gsutil notification create -t gcs-raw-files \
  -f json -e OBJECT_FINALIZE gs://medicaid-data/raw/
```

### Cloud Function Errors

```bash
# View detailed logs
gcloud functions logs read gcs-to-bigquery \
  --filter="severity>=ERROR" \
  --format="table(timeUtc, severity, log)"

# Check function configuration
gcloud functions describe gcs-to-bigquery \
  --format="yaml(environmentVariables, serviceAccountEmail)"

# Redeploy function
cd cloud-functions/gcs-to-bq
gcloud functions deploy gcs-to-bigquery \
  --runtime python310 \
  --trigger-topic gcs-raw-files \
  --entry-point process_gcs_file
```

### Dataproc Job Failures

```bash
# List recent jobs
gcloud dataproc jobs list --region=us-central1 --limit=10

# View job details
gcloud dataproc jobs describe JOB_ID --region=us-central1

# View job logs
gcloud dataproc jobs wait JOB_ID --region=us-central1

# Check cluster status
gcloud dataproc clusters list --region=us-central1
```

### Authentication Issues

```bash
# Re-authenticate
gcloud auth login
gcloud auth application-default login

# Verify service account permissions
gcloud projects get-iam-policy gcp-project-deliverable

# Check Workload Identity binding
kubectl describe serviceaccount dashboard-ksa

# Verify GKE authentication
gcloud container clusters get-credentials medicaid-dashboard-cluster \
  --zone=us-central1-a
```
- **Auto-scaling** (1-4 replicas)

## ü§ñ RAG AI Assistant Features ‚ú® (In Progress)!

The RAG (Retrieval-Augmented Generation) system enables natural language queries over your drug database:

### Key Features
- **Natural Language Q&A**: Ask questions in plain English
- **Semantic Search**: Understands intent, not just keywords
- **Context-Aware**: Multi-turn conversations with history
- **Source Citations**: Shows which drugs informed the answer
- **Configurable**: Adjust retrieval count and creativity

### Technology Stack
- **Embeddings**: Vertex AI text-embedding-gecko@003
- **Vector Store**: FAISS for fast similarity search
- **LLM**: Vertex AI Gemini Pro 1.5
- **Framework**: Complete Jupyter notebook + optional FastAPI

### Example Queries
```
"What are pain medications in tablet form?"
"Show me affordable antibiotics under $1"
"Compare generic vs brand blood pressure drugs"
"What injectable diabetes medications are available?"
```

### Quick Start
```bash
cd notebooks
python setup_rag.py
jupyter notebook drug_rag_system.ipynb
```

**See [notebooks/QUICKSTART.md](notebooks/QUICKSTART.md) for 15-minute setup guide.**

## ÔøΩ Estimated Costs

**Monthly (Moderate Usage)**:
- Cloud Composer: $300-400
- Dataproc: $50-100 (ephemeral)
- BigQuery: $30-60
- GKE: $100-150
- Cloud Run Functions: $5-10
- Vertex AI (RAG): $30-80
- **Total**: ~$521-815/month

**Cost Optimization**:
- Use preemptible VMs for Dataproc
- Lifecycle policies for GCS
- BigQuery clustering/partitioning
- Scale Composer during off-hours

## üß™ Technology Stack

### Pipeline
- Cloud Composer (Airflow 2.x), Dataproc (Spark 3.x), BigQuery, GCS, Pub/Sub, Cloud Run Functions

### Dashboard
- Streamlit, Plotly, Docker, GKE, Artifact Registry

### AI
- Vertex AI (Gecko embeddings, Gemini Pro), FAISS, Jupyter

---

**Built with ‚ù§Ô∏è on Google Cloud Platform**

All scripts are in the `dashboard/` directory:

```powershell
cd dashboard

# Verify prerequisites
.\verify-setup.ps1

# Build Docker image (uses Cloud Build, no local Docker!)
.\build-image.ps1

# Deploy everything to GKE
.\deploy-gke.ps1

# Daily operations
.\manage-dashboard.ps1 -Action status      # Check status
.\manage-dashboard.ps1 -Action logs        # View logs
.\manage-dashboard.ps1 -Action restart     # Restart
.\manage-dashboard.ps1 -Action scale -Replicas 3   # Scale
.\manage-dashboard.ps1 -Action url         # Get URL
```

## üìñ Documentation

### Dashboard
- **[QUICKSTART.md](dashboard/QUICKSTART.md)** - 5-minute deployment guide ‚ö°
- **[README.md](dashboard/README.md)** - Complete dashboard documentation
- **[DEPLOYMENT.md](dashboard/DEPLOYMENT.md)** - Detailed deployment instructions
- **[TOOLKIT.md](dashboard/TOOLKIT.md)** - Complete script reference

### Pipeline
- **[Dataproc Job](dataproc/data_processing_job.py)** - PySpark enrichment logic
- **[Extraction DAG](composer/dags/medicaid_data_dag.py)** - API extraction
- **[Enrichment DAG](composer/dags/medicaid_enrichment_dag.py)** - Data processing

## üîß Configuration

### GCP Resources

| Resource | Name/ID | Purpose |
|----------|---------|---------|
| Project | `gcp-project-deliverable` | Main GCP project |
| GCS Bucket | `gcp-project-deliverable-medicaid-data` | Raw data storage |
| BigQuery Dataset | `medicaid_data` | All tables |
| BigQuery Table (Staging) | `medicaid_raw` | Raw API data |
| BigQuery Table (Enriched) | `enriched_drug_data` | Processed data |
| Dataproc Cluster | `medicaid-processing-cluster` | PySpark processing |
| GKE Cluster | `medicaid-dashboard-cluster` | Dashboard hosting |
| Service Account | `data-pipeline-sa` | Pipeline execution |

## üö® Troubleshooting

### Dashboard Issues

```powershell
cd dashboard

# Check status
.\manage-dashboard.ps1 -Action status

# View logs
.\manage-dashboard.ps1 -Action logs

# Verify setup
.\verify-setup.ps1

# Restart
.\manage-dashboard.ps1 -Action restart
```

### Authentication Issues

```powershell
# Re-authenticate
gcloud auth login
gcloud auth application-default login

# Verify service account permissions
gcloud projects get-iam-policy gcp-project-deliverable
```

### More Help

See detailed troubleshooting in:
- [dashboard/DEPLOYMENT.md](dashboard/DEPLOYMENT.md) - Deployment issues
- [dashboard/TOOLKIT.md](dashboard/TOOLKIT.md) - Script issues

## üí∞ Cost Estimate

### Monthly Costs (Approximate)

| Service | Cost |
|---------|------|
| GKE (2 e2-standard-2 nodes) | ~$150 |
| Cloud Storage | ~$5 |
| BigQuery (storage + queries) | ~$10-20 |
| Dataproc (on-demand) | ~$5-10 |
| LoadBalancer | ~$18 |
| Cloud Build | Free tier |
| **Total** | **~$190-200/month** |

### Cost Optimization

```powershell
# Scale down when not in use
.\dashboard\manage-dashboard.ps1 -Action scale -Replicas 0

# Use smaller machines
--machine-type=e2-small

# Delete cluster when not needed
gcloud container clusters delete medicaid-dashboard-cluster --region=us-central1
```

## üîê Security

### Implemented
- ‚úÖ Workload Identity (no service account keys)
- ‚úÖ Least privilege IAM roles
- ‚úÖ Secrets excluded from Git/Docker
- ‚úÖ Resource limits on pods
- ‚úÖ Health checks

### Recommended Enhancements
- [ ] Enable HTTPS with managed certificates
- [ ] Add Cloud IAP for authentication
- [ ] Use Secret Manager
- [ ] Configure VPC Service Controls
- [ ] Enable Binary Authorization

## üéì Next Steps

1. ‚úÖ **Deploy Dashboard:** `cd dashboard && .\deploy-gke.ps1`
2. ‚¨ú **Add HTTPS:** Configure Ingress with SSL
3. ‚¨ú **Add Authentication:** Use Cloud IAP
4. ‚¨ú **Set up Monitoring:** Enable Cloud Monitoring
5. ‚¨ú **Add CI/CD:** Automate with Cloud Build triggers
6. ‚¨ú **Optimize Costs:** Right-size resources

## üìû Support

For issues:
1. Check documentation (QUICKSTART, README, DEPLOYMENT, TOOLKIT)
2. Run `.\dashboard\verify-setup.ps1`
3. View logs: `.\dashboard\manage-dashboard.ps1 -Action logs`
4. Check GCP Console for service status

## üèÜ Key Features

- ‚úÖ Production-grade data pipeline
- ‚úÖ Automated with Airflow/Composer
- ‚úÖ Scalable processing with Dataproc
- ‚úÖ Interactive Streamlit dashboard
- ‚úÖ Kubernetes deployment (GKE)
- ‚úÖ Secure Workload Identity
- ‚úÖ Auto-scaling and health checks
- ‚úÖ **No Docker required** (Cloud Build)
- ‚úÖ Easy management scripts
- ‚úÖ Comprehensive documentation

---

**Ready to deploy?** Start here: [dashboard/QUICKSTART.md](dashboard/QUICKSTART.md)
